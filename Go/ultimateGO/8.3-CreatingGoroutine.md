\- So now that we've reviewed how the operating system schedules work, and the Go schedules work, and how it sits on top. We now want to start learning how we, manage concurrency in Go. But I want you to understand something here, Go routines are chaos. Look, I've got five kids. When I tell people I have five kids, usually what happens is the person bends over and goes, oh my god, oh my god, you've got five kids? I've got one, how do you do that? And I always say, I just travel a lot and get out of town. Right, I just get out of town. Well you can't get out of town, when you're dealing with managing concurrency and multi-threaded software in Go. You're in town, you're in the house. You've got to deal with the chaos. I always like to think of Go routines as children. If you don't have children yourself, I'm sure you've got nieces and nephews, right? And you know that children are chaos. Like, one's running out to the pool, one's running up the stairs, one's running across the street, one's about to pull off their diaper. Which one are you going after? Like, I'm going after the diaper, man, I know that is a big mess. But the reality is you only get one. You only get to go after one of those kids, when they're running in parallel, right, and there is only one of you. So, really what we're gonna be talking about, for the rest of this section, is really, what I always say, a parenting class. I've gotta teach you how to manage your children. Every time you bring a Go routine into your program, you're bringing a child into this world. This is now parenting 101. I've got to teach you how to keep these children safe, I've got to teach you how to keep the house from burning down, because multi-threaded software development is complex. Now I told you there's two aspects to this, there is synchronization and there is orchestration, and there's tons of rules around managing concurrency. Like this one, you're not allowed to create a Go routine, or bring a child into this world, unless you know how and when. Right, you're not allowed to create a Go routine, unless you can tell me how and when that Go routine is going to be terminated, before the Go program shuts down. My equivalent to that is, you're not allowed to lock the house up at night, until you know that those Go routines, those children, are safely tucked away in their beds. You've gotta be managing this. You gotta have known control over anything that's going. Synchronization, orchestration. So what I'm gonna show you right now is some basic orchestration using a weight group. And to show you how we are going to like, keep our programs running until we know that the Go routines, or these paths of execution, are done. This is basic orchestration using weight groups. We'll also learn how to create Go routines. After this though, we've got to learn about data races. We've got to start learning about synchronization and eventually orchestration, because without it, you're going to have some really nasty code, complexity, bugs. (groans) But here we are, let me do my best here to try to get you where you need to be so you can start really being successful here, with a less is more, less complexity is more attitude. So let's start with this program right here. Now I, on my Mac here, I have an eight core machine and I wanna run some of this code as single-threaded. So what you're seeing on line 17, is me calling the **GOMAXPROCS** function, from the run-time package, telling it to knock my Ps from eight to one, single-threaded. And it's capitalized because it represents an environmental variable that this can override. We used to have to use this back in the day because, prior to 1.5, your Go program only came up single-threaded, or one P, regardless of the number of cores. From 1.5 since, we match Ps to cores that are identified on the host machine. Okay, now what you're seeing next to line 23 in the main function, and again I apologize. This is being done in a net, so it happens before main. In the main function here, on line 23, what you see is the weight group. In fact, we are creating a value of type weight groups, set to its zero value, naming it the variable WG. And we're calling wg.Add(2). I don't want to see you calling Add(1), Add(1), Add(1), , Add(1). In other words, the weight group is a synchronous counting semaphore. We're gonna keep a count of all the existing Go routines that we create. So we know that we're not going to shut down until that count goes back down to zero. So I want to do Add one time for the number of Go routines we're gonna create. If you don't know how many Go routines you're gonna create, stop, you're going down a very bad path and we're not gonna call Add(1) as they get created. We call Add one time, upfront. There it is. So now we know we're gonna be creating two new Go routines in this program and I don't want this program to end until those Go routines are finished doing their work. And this is where we get the wait call on line 42. The wait call is a blocking call. A weight group has three API's, add, wait, and done. Add is adding to the counting semaphore, done is decrementing, and wait will block until the count goes from two to zero. Again, we don't want main returning until we know those other Go routines are done. What you're seeing now on line 29 and 35 is the declaration of a literal function, then the execution of that literal function, remember literal means unnamed, these are unnamed functions, and then the use of the keyword go in front of the function call. This is essentially going to define, call, and then execute, this function as a Go routine. A separate path of execution. I also want you to notice we're using closures. I like closures, I think it helps simplify how these literal functions access data. You can pass it in, we're gonna have to do that at some point today. Closure bugs can be nasty, but the golint tool, which you should be using, can detect closure bugs, and you'll be okay. So what these two Go routines do is call a named function called lowercase and uppercase. These functions aren't doing anything special. They're just displaying the alphabet in lowercase or uppercase letters three times. Look at this full structure of this Go program. Orchestration with the weight group, we're gonna create two Go routines. Go ahead, two Go routines. Go ahead and create the first Go routine. Have it execute lowercase and through our closures call done to decrement the weight from two to one. Then you run uppercase, decrement the weight groups from one to zero, and you wait here until those Go routines report they're done by decrementing the weight group. Understand when all things are equal, we do not know what the schedule is going to do. There is no predictability on whether this function is gonna execute first, or this function is gonna execute first. They're both gonna be, essentially, created within a very narrow set of nanoseconds of time here. ==s==So by the time the main Go routine goes wait, okay, which is gonna force a context switch, we don't know what the schedule is gonna do. Whether it's lowercase or uppercase. Alright, let's run this program. I'm gonna go get the path of this program from the repo. I'm gonna come over to the terminal window, I'm gonna call go build, then I'm gonna run it. What I want you to notice is that the second Go routine that we created, this one here which runs uppercase, the second one we created, is the one that ran first. So you can see that this is a concurrent program. It didn't run in the order that we put things in, the schedule turned around and did that. Now I could run this a million times, and maybe it runs the same, maybe it doesn't. Again, when all things are equal, the scheduler is going to look and feel preemptive. It's undeterministic. Okay, great, so we've seen this. But what happens if I turn around and I forget to call weight? Look, I forget to call weight, I pull it out. Let's see what happens here. Go build, run it, there's no output. Start, waiting, terminating. What happened? Well this time, when I pulled the wait call out, the main Go routine got to finish its time slice, which meant main returning, which meant this program terminated. These two paths of execution that we created never got a chance to run. This is almost a race condition too, because we're racing to see if this program ends, before this scheduler makes a decision. Now, I kinda understand that orchestration and synchronization must be guaranteed, or it doesn't work. It might appear you program is working, but without the guarantee, real guarantees of organization and synchronization, you're just getting lucky. I want to show you this idea of luck by using a function called Gosched. No I don't want you using the Gosched runtime function in your production code. This, however, can be brilliant when running, or building, tests that have to create chaos because what Gosched does, is it makes a cooperating request. It is telling the scheduler, I am willing to give up my time, on the M, but the scheduler doesn't have to listen. The scheduler can do what ever it wants. This is a request, this is not a demand. Wait was a demand. Wait said I want to wait here, I demand that we wait here, until this semaphore count goes to zero. Gosched is a request. I request that you let some other path of execution run. But it's not a demand. Let's see what happens when I add it. It looks like the program worked. It looks like our request to run the other Go routines were taken. But understand something, there's no guarantees here. The scheduler, I could run this program 1000 times, and the scheduler can make any decision it wants, at any given time. So don't think this program worked, because it didn't, we got lucky. This is why multi-threaded software development is complicated. We need the ability to know when we need to demand and when we don't need to demand and demanding comes form synchronization and orchestration. Right now there is no orchestration going on here, this is purely a request. However, again, we can create a huge amount of chaos, in our Go tests, by causing the Go scheduler to just, in our kind of requesting way, randomly make context switches. Don't do this, there's no guarantees here. That was bad code. Let's go back to this. Now, what happens if I forget to call done? This happens in Go programs, right? I forget to call done, I forget this program, this Go routine forgets to report that it's done. I don't know, let's build it again. Let's run it. Notice this time that I have a dead lock situation. Yes I have a dead lock, and the stat trace is gonna tell us that our dead lock is on line, let me bring this out a little bit here, on line 42. Let's go look on line 42. The dead lock is on the weight, it's absolutely right. The weight group can no longer get to zero because we are no longer calling done. Now the Go runtime has a very simple dead lock detector. It's simple because all it can identify is when every single Go routine is now in a waiting state and can never move back into a runnable state. If you have one Go routine that can continue to run, we walk away from this dead lock detection. So we wanna try hard not to create Go routines in our services that kinda spin on a timer. You're walking away from some of this dead lock detection. Yes, it is simple dead lock detection, but it is there. You're seeing it, this is bad. The same thing can happen if we don't set the weight count appropriately. I mean look at this, let's say I set the weight count to one. That means as soon as one of these Go routines is finished, the weight group will go to zero. ==s==Again, we're gonna have some chaos, because we're not really managing concurrency. We're not waiting for both Go routines to finish. Look, the Go routine doing capital letters just finished and we don't see the next one run. This is all bad races, this is not proper orchestration. Synchronization, orchestration, is about demands, around guarantees, that things happen in the order we need or we're waiting for things to finish before we move on. So the weight group is a great way of doing orchestration when we don't need anything back from the Go routine, we just need to maintain the semaphore count. Now, let's add a little more complexity to this piece of code here. What I'm gonna do is spell example, right. What I'm gonna do is come in here and look at this next example. Okay, brilliant, example two. Now, we're gonna take the base pattern again. of weight group orchestration. Notice I'm knocking my Ps down to one, I've got my weight group, we Add(2), weight group orchestration here. I've got my two Go routines being called and run as an independent path of execution and then on line 42, we wait, brilliant. But this time, we're gonna do a little bit more work. This time we're calling printPrime. And the printPrime function identifies prime numbers from two to 5,000 and displays them on the screen. There are lots of system calls going on here and this work is gonna take a lot longer than the other work. What's nice about this program is we're going to be able to see context switches and see that we're not going to be able to predict when the context switch is going to happen. So, let's build this program. Here it is, I build it, I run it. There's a bunch of output. I'm gonna go to the top and you can see the second Go routine started again. That's, from my perspective, random. And what I'm doing is looking to see when a context switch happens. And it looks like B is getting a really good run here, and I'm gonna keep, oh, there it is. Okay, so we now have a context switch after the A Go routine got to prime number 3,833. Let's write the right one here, 3,833. Then the B Go routine now contexts to A. Now if I keep scrolling, what do we see, what do we see, what do we see. Does the A Go routine get to finish? Nope it doesn't, there it is. There's another context switch. A went to, what is that again right there, 3041, 3041, there's a context switch. Then B picks up right where it left off. B finishes, and then A finishes. So then B finishes, and A finishes. So we did see some context switches. What I want to really show you is that these context switches are not predictable. I'm gonna run this again and its not gonna be 3,833. In fact, I have no idea what it's going to be. It's really not possible to predict the output of this program. So, let's run it again. Let's scroll to the top. B started again, that's fine, and here's our context switch. And where did it happen? It happened at 3,691. So this time it happened at 3,691. ==s== Again, I couldn't even predict that and if I just look to see if A gets to finish or not. Look at we're doing here, oh, there it is right there again. I see that we're at 4,159. 4,159, look, A got a much larger run on this run here. I imagine that it's gonna finish, it finishes, it finishes, okay. My point here is that even though this is a cooperating scheduler, because the schedule is doing the cooperating and not us, it looks and feels preemptive. When all things are equal, it is undeterministic to know when the scheduler is going to make a scheduling decision. I just showed you that with this piece of code. I have no idea if I even run it again, where this is gonna happen. And I've run this before where I even see another set of context switches before it finishes. But let's now bring this completely full circle and go to one more example. This time, let's go back to the original program we had but just make two minor modifications. One, lets run this now in parallel. Let's use two Ps, which means two threads. At this point now, what we're gonna have is not just one P per thread, but two Ps, P one, there it is, M, P two, M, and then since I'm on a multi-core machine here, these two Ms are going to be able to run in parallel. In fact, our Go routines are gonna be able to run in parallel. So, maxprocs two, weight group orchestration, we're gonna create two Go routines, there it is, I'm using a full literal function this time to do all of the work. There it is, do the alphabet in lowercase three times, then report that we're done. Second Go routine, do everything in uppercase letters, then report that we're done and then we have the weight. So in this case, these two Go routines, they're gonna be running in parallel, making system calls, which means the operating system is going to be handling synchronization on the system calls. We should see a mix of output, when I run this program, which we didn't see before. If I run this enough times, we should see, I'm gonna look down here, you should see here that we now have a mix of output. This one's a really nice one, we see a good mix of output, right here on this line. You can see lowercase, uppercase, lowercase, uppercase. They're running in parallel now. This has almost nothing to do with the Go schedule, at this point. It's the operating system allowing these threads to run in parallel and their system calls are now being synchronized. So, you can see here that now that we've went from one P, or thread, to two, we're now a multi-threaded Go program. Go routines can run in parallel and this is where synchronization, orchestration really, really become important. See, Go made it super simple, to create these paths of executions, or Go routines, but you still have the burden and no language can take care of this, no runtime can take care of this. You still have the burden of synchronization and orchestration. I've shown you weight group orchestration. So, the next thing I really have to show you is how to deal with synchronization in the language.

我得教你如何保证这些孩子的安全，我得教你如何保证房子不被烧毁，因为多线程软件开发很复杂。现在我告诉你有两个方面，有同步，有协调，有大量的规则围绕着管理并发性。像这个，你不允许创建一个围棋例程，或者把一个孩子带到这个世界上，除非你知道怎么做，什么时候做。对，你不允许创建一个围棋例程，除非你能在围棋程序关闭之前，告诉我这个围棋例程将如何以及何时终止。我的意思是，你不能在晚上把房子锁起来 直到你知道那些围棋程序，那些孩子们，都安全地躺在床上了。你必须管理好这个。你必须对任何事情有已知的控制。同步化，协调化。所以我现在要向你们展示的是一些基本的协调，使用一个重量组。并向你展示我们如何让我们的程序继续运行，直到我们知道Go例程，或者这些执行路径已经完成。这就是使用权重组的基本编排。我们还将学习如何创建围棋例程。不过在这之后，我们要学习数据竞赛。我们要开始学习同步和最终的协调，因为如果没有同步，你会有一些非常讨厌的代码，复杂度和错误。(呻吟)但是我们在这里，让我尽我最大的努力来尝试让你达到你所需要的状态，这样你就可以开始真正的成功，以一种少即是多，少复杂即是多的态度。所以，让我们从这个程序开始。现在，我，在我的Mac上，我有一个八核的机器，我想以单线程的方式运行其中的一些代码。



所以我现在要向你展示的是一些使用权重组的基本编排。并向你展示我们如何让我们的程序一直运行，直到我们知道Go例程或这些执行路径已经完成。这就是使用权重组的基本编排。我们还将学习如何创建围棋例程。不过在这之后，我们要学习数据竞赛。我们要开始学习同步和最终的协调，因为如果没有同步，你会有一些非常讨厌的代码，复杂度和错误。(呻吟)但是我们在这里，让我尽我最大的努力来尝试让你达到你所需要的状态，这样你就可以开始真正的成功，以一种少即是多，少复杂即是多的态度。所以，让我们从这个程序开始。现在，我，在我的Mac上，我有一个八核的机器，我想以单线程的方式运行一些代码。所以你在第17行看到的，是我在运行时包中调用GOMAXPROCS函数，让它把我的Ps从八核变成一核，单线程。而且它是大写的，因为它代表了一个环境变量，这个变量可以覆盖。当年我们之所以要用这个，是因为在1.5之前，你的围棋程序不管核数多少，都只能上来一个单线程，或者一个P。从1.5以后，我们把Ps和主机上识别的核进行匹配。好了，现在你看到的是主函数的第23行旁边，再次表示歉意。这是在net中进行的，所以它发生在main之前。在主函数这里，第23行，你看到的是权重组。事实上，我们正在创建一个类型为权重组的值，将其设置为零值，将其命名为变量WG。然后我们调用WG.Add(2)。我不希望看到你调用Add(1)，Add(1)，Add(1)， ，Add(1)。换句话说，权重组是一个同步计数信号体。我们要对所有我们创建的现有围棋例程进行计数。所以我们知道，我们不会关闭，直到这个计数回落到零。所以我想对我们要创建的围棋例程数量进行一次添加。如果你不知道要创建多少个围棋例程，停止，你会走在一条非常糟糕的道路上，我们不会在它们被创建时调用 Add(1) 。我们只调用 Add 一次，在前面。就是这样。所以现在我们知道我们将在程序中创建两个新的围棋例程，我不希望程序结束，直到这些围棋例程完成工作。这就是我们在第42行得到等待调用的地方。等待调用是一个阻塞调用。一个权重组有三个API，分别是add，wait和done。add是向计数信号体添加，done是递减，wait会阻塞，直到计数从2变成0。同样，我们不希望main返回，直到我们知道其他Go例程已经完成。你现在在第29行和第35行看到的是一个文字函数的声明，然后执行这个文字函数，记住literal的意思是未命名，这些都是未命名的函数，然后在函数调用前面使用关键字go。这实质上是要把这个函数定义，调用，然后执行，作为一个Go例程。一个单独的执行路径。我还想让你注意到我们使用了闭包。我喜欢闭包，我认为它有助于简化这些文字函数访问数据的方式。你可以把它传递进来，我们今天在某些时候必须这么做。闭包错误可能会很严重，但是你应该使用的golint工具可以检测到闭包错误，你就不会有事了。所以这两个Go例程要做的是调用一个名为lowercase和uppercase的命名函数。这些函数并没有做什么特别的事情。它们只是将字母表的小写字母或大写字母显示三次。看看这个围棋程序的完整结构。用权重组进行编排，我们要创建两个围棋例程。来吧，两个围棋例程。来吧，建立第一个围棋程序 让它执行小写字母，然后通过我们的闭包调用done，将权重从2减为1。然后执行大写，将权重组从1减为0，然后在这里等待，直到这些围棋例程报告他们已经完成了权重组的递减。要明白当所有的东西都相同的时候，我们不知道这个程序要做什么。我们无法预测是这个函数先执行，还是这个函数先执行。它们都会被创建，本质上，是在一个非常狭窄的纳秒时间内创建的。

到了主围棋例程进入等待，好吧，这将强制进行上下文切换，我们不知道时间表要做什么。不管是小写还是大写。好吧，让我们运行这个程序。我去从回购中获取这个程序的路径。我将来到终端窗口，我将调用go build，然后我将运行它。我想让你注意到的是，我们创建的第二个Go例程，这个运行大写字母的例程，是我们创建的第二个例程，是第一个运行的。所以你可以看到，这是一个并发程序。它并不是按照我们放的顺序运行的，日程表转过来就可以了。现在我可以运行这个程序一百万次，也许它运行的顺序是一样的，也许不一样。同样，当所有的事情都相同的时候，调度器要看起来和感觉是先发制人的。它是不确定的 好的，很好，所以我们已经看到了这一点。但如果我转过身来忘记调用权重会怎样？听着，我忘了称体重，我就把它拉出来。让我们看看会发生什么。去构建，运行它，没有输出。开始，等待，终止。发生了什么？这次，当我拉出等待调用时，主围棋例程完成了它的时间片，这意味着主程序返回，意味着这个程序终止。我们创建的这两条执行路径从来没有机会运行。这几乎也是一个竞赛条件，因为我们在这个调度器做出决定之前，就在比赛看这个程序是否结束。现在，我有点明白了，编排和同步必须保证，否则就不行。可能看起来你的程序在工作，但是如果没有保证，没有真正的组织和同步的保证，你只是在侥幸。我想用一个叫Gosched的函数来告诉你这个运气的概念。不，我不希望你在生产代码中使用Gosched运行时函数。然而，当运行或构建必须制造混乱的测试时，这可以是辉煌的，因为Gosched所做的，是它提出一个合作请求。它是在告诉调度器，我愿意放弃我的时间，在M上，但调度器不用听。调度器可以做任何它想做的事情。这是个请求，这不是需求。等等是需求。Wait说我想在这里等，我要求我们在这里等，直到这个旗语数归零。Gosched是一个请求。我要求你让其他的执行路径运行。但这不是要求。让我们看看我加进去后会发生什么。看起来程序成功了。看起来我们运行其他围棋例程的请求被采纳了。但你要明白，这里没有保证。调度器，我可以运行这个程序1000次，调度器可以在任何时间做出任何决定。所以不要以为这个程序成功了，因为它没有成功，我们运气好。这就是为什么多线程软件开发很复杂的原因。我们需要有能力知道什么时候需要需求，什么时候不需要需求，而需求来自于同步和协调的形式。现在这里没有进行编排，这纯粹是一个需求。然而，在我们的围棋测试中，我们又可以通过使围棋调度器以我们这种请求的方式，随机地进行上下文切换，来制造大量的混乱。不要这样做，这里没有保证。这是不好的代码。让我们回到这个问题上。现在，如果我忘了调用done会怎么样？这在Go程序中也会发生，对吧？我忘了调用done，我忘了这个程序，这个Go例程忘了报告它已经完成了。我不知道，我们再建一次吧。我们运行一下。注意这次我出现了死锁的情况。是的，我有一个死锁，统计跟踪会告诉我们，我们的死锁在第42行，让我把这个拿出来一点。让我们看看第42行 死锁在重量上，绝对正确。权重组不能再到零了，因为我们不再调用done了。现在Go运行时有一个非常简单的死锁检测器。它之所以简单，是因为它能识别的是，当每一个Go例程现在都处于等待状态，永远无法再进入可运行状态。如果你有一个围棋例程可以继续运行，我们就可以从这个死锁检测中走出来。所以我们要努力避免在我们的服务中创建围棋例程，这些例程有点像在计时器上旋转。你正在从这种死锁检测中走出来。是的，这只是简单的死锁检测，但它确实存在。你看到了，这很糟糕。如果我们没有适当地设置权重计数，同样的事情也会发生。我的意思是看看这个，比如说我把权重数设置为1。也就是说，只要其中一个围棋程序完成了，重量组就会归零。

